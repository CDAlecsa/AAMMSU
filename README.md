# AAMMSU optimizer (from the paper : ....)

## Neural networks architectures that are available:
- Logistic Regression: <br />
https://towardsdatascience.com/logistic-regression-on-mnist-with-pytorch-b048327f8d19 <br /> https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_logistic_regression/ <br />
- CNN:
- VGG: https://github.com/uclaml/Padam/blob/master/models/vgg.py
- ResNet: https://github.com/uclaml/Padam/blob/master/models/resnet.py

## Datasets:
- MNIST: http://yann.lecun.com/exdb/mnist/
- CIFAR10: https://www.cs.toronto.edu/~kriz/cifar.html

## For the optimizer current implementation, we have used the following:
https://github.com/pytorch/pytorch/blob/99711133403eff8474af0e710a45d367f4fb5e66/torch/optim/_functional.py#L54 <br />
https://github.com/jettify/pytorch-optimizer/blob/master/torch_optimizer/diffgrad.py



